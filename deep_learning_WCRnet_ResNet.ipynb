{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enter the data folder name and WCR information\n",
    "\n",
    "# select fold\n",
    "fold_idx = 1\n",
    "\n",
    "# Load the data folder path\n",
    "path = os.getcwd()\n",
    "train_path_upper = path + f'/data_mortar/FOLD_{fold_idx}/train'\n",
    "valid_path_upper = path + f'/data_mortar/FOLD_{fold_idx}/valid'\n",
    "test_path_upper = path + f'/data_mortar/FOLD_{fold_idx}/test'\n",
    "\n",
    "# Set the name of the training model file to save.\n",
    "model_save_name = \"WCRnet_ResNet.h5\"\n",
    "\n",
    "# WCR information\n",
    "WC_name_tag = [40, 42.5, 45, 47.5, 50, 52.5, 55, 57.5, 60]\n",
    "\n",
    "# Fit the random seed\n",
    "seed_data = 4885\n",
    "random.seed(seed_data)\n",
    "np.random.seed(seed_data)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed_data)\n",
    "tf.random.set_seed(seed_data)\n",
    "\n",
    "model_save_dir = path + f'/save_models/{model_save_name}'\n",
    "\n",
    "# Layer paramter for WCRnet\n",
    "layer_list = [3, 4, 6, 3]\n",
    "\n",
    "# Parameter for Training\n",
    "epochs = 1000                 # training epochs\n",
    "batch_sizes = 1024            # batch size\n",
    "initial_learning_rate = 0.01   # initial learning rate\n",
    "input_shape = 6               # input shape of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data normalization\n",
    "\n",
    "# Normalize to the minimum and maximum sensor measurement values.\n",
    "def sense_min_max_Normalization(input_data, min_value, max_value):\n",
    "    data = (input_data - min_value) / (max_value - min_value) \n",
    "    \n",
    "    return data\n",
    "\n",
    "def data_set_normalization(data):\n",
    "    # sensor_min_value\n",
    "    vwc_min = 0\n",
    "    ec_min = 0\n",
    "    salinity_min = 0\n",
    "    tds_min = 0\n",
    "    epsilon_min = 0\n",
    "    temp_min = -40\n",
    "    \n",
    "    # sensor_max_value\n",
    "    vwc_max = 100\n",
    "    ec_max = 20000\n",
    "    salinity_max = 20000\n",
    "    tds_max = 20000\n",
    "    temp_max = 80\n",
    "    epsilon_max = 82\n",
    "    \n",
    "    # sensor_normalization \n",
    "    data['TEMP'] = sense_min_max_Normalization(data['TEMP'],temp_min,temp_max)\n",
    "    data['EC'] = sense_min_max_Normalization(data['EC'],ec_min,ec_max)\n",
    "    data['VWC'] = sense_min_max_Normalization(data['VWC'],vwc_min,vwc_max)\n",
    "    data['TDS'] = sense_min_max_Normalization(data['TDS'],tds_min,tds_max)\n",
    "    data['SALINITY'] = sense_min_max_Normalization(data['SALINITY'],salinity_min,salinity_max)\n",
    "    data['EPSILON'] = sense_min_max_Normalization(data['EPSILON'],epsilon_min,epsilon_max)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WC_ratio</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>EC</th>\n",
       "      <th>VWC</th>\n",
       "      <th>TDS</th>\n",
       "      <th>SALINITY</th>\n",
       "      <th>EPSILON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.514917</td>\n",
       "      <td>0.19240</td>\n",
       "      <td>0.6391</td>\n",
       "      <td>0.09620</td>\n",
       "      <td>0.10580</td>\n",
       "      <td>0.720488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.514417</td>\n",
       "      <td>0.19580</td>\n",
       "      <td>0.6512</td>\n",
       "      <td>0.09790</td>\n",
       "      <td>0.10765</td>\n",
       "      <td>0.736098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.514417</td>\n",
       "      <td>0.19600</td>\n",
       "      <td>0.6549</td>\n",
       "      <td>0.09800</td>\n",
       "      <td>0.10780</td>\n",
       "      <td>0.740610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.514250</td>\n",
       "      <td>0.19630</td>\n",
       "      <td>0.6568</td>\n",
       "      <td>0.09815</td>\n",
       "      <td>0.10795</td>\n",
       "      <td>0.742927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.513833</td>\n",
       "      <td>0.19660</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.09830</td>\n",
       "      <td>0.10810</td>\n",
       "      <td>0.745244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.495333</td>\n",
       "      <td>0.28745</td>\n",
       "      <td>0.9264</td>\n",
       "      <td>0.14370</td>\n",
       "      <td>0.15805</td>\n",
       "      <td>0.955366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.495333</td>\n",
       "      <td>0.28750</td>\n",
       "      <td>0.9374</td>\n",
       "      <td>0.14375</td>\n",
       "      <td>0.15810</td>\n",
       "      <td>0.961341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.495333</td>\n",
       "      <td>0.28795</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>0.14395</td>\n",
       "      <td>0.15835</td>\n",
       "      <td>0.958415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.495333</td>\n",
       "      <td>0.28795</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>0.14395</td>\n",
       "      <td>0.15835</td>\n",
       "      <td>0.958415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.495333</td>\n",
       "      <td>0.28750</td>\n",
       "      <td>0.9374</td>\n",
       "      <td>0.14375</td>\n",
       "      <td>0.15810</td>\n",
       "      <td>0.961341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13347 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     WC_ratio      TEMP       EC     VWC      TDS  SALINITY   EPSILON\n",
       "0         0.4  0.514917  0.19240  0.6391  0.09620   0.10580  0.720488\n",
       "1         0.4  0.514417  0.19580  0.6512  0.09790   0.10765  0.736098\n",
       "2         0.4  0.514417  0.19600  0.6549  0.09800   0.10780  0.740610\n",
       "3         0.4  0.514250  0.19630  0.6568  0.09815   0.10795  0.742927\n",
       "4         0.4  0.513833  0.19660  0.6587  0.09830   0.10810  0.745244\n",
       "..        ...       ...      ...     ...      ...       ...       ...\n",
       "468       0.6  0.495333  0.28745  0.9264  0.14370   0.15805  0.955366\n",
       "469       0.6  0.495333  0.28750  0.9374  0.14375   0.15810  0.961341\n",
       "470       0.6  0.495333  0.28795  0.9320  0.14395   0.15835  0.958415\n",
       "471       0.6  0.495333  0.28795  0.9320  0.14395   0.15835  0.958415\n",
       "472       0.6  0.495333  0.28750  0.9374  0.14375   0.15810  0.961341\n",
       "\n",
       "[13347 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load FDR Data for Train\n",
    "\n",
    "path_list = []\n",
    "path_under=os.listdir(train_path_upper)\n",
    "\n",
    "# load data_path\n",
    "for i in range(len(path_under)): # collect under directory file path\n",
    "    path_sub=os.listdir(train_path_upper+'/'+path_under[i])\n",
    "    \n",
    "    for j in range(len(path_sub)):\n",
    "        path_list.append(train_path_upper+'/'+path_under[i]+'/'+path_sub[j])\n",
    "\n",
    "# make zero matrix\n",
    "data_list = [0]*len(path_list)\n",
    "rand_x_data_list = [0]*len(path_list)\n",
    "rand_y_data_list = [0]*len(path_list)\n",
    "\n",
    "# load data_value\n",
    "for i,j in enumerate(path_list):\n",
    "    data_list[i] =pd.read_csv(j)\n",
    "    data_list[i] = data_set_normalization(data_list[i])\n",
    "    \n",
    "train_data = pd.concat(data_list)\n",
    "\n",
    "# Print the data format\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WC_ratio</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>EC</th>\n",
       "      <th>VWC</th>\n",
       "      <th>TDS</th>\n",
       "      <th>SALINITY</th>\n",
       "      <th>EPSILON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.491083</td>\n",
       "      <td>0.18165</td>\n",
       "      <td>0.6014</td>\n",
       "      <td>0.09080</td>\n",
       "      <td>0.09990</td>\n",
       "      <td>0.665610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.491083</td>\n",
       "      <td>0.18250</td>\n",
       "      <td>0.6014</td>\n",
       "      <td>0.09125</td>\n",
       "      <td>0.10035</td>\n",
       "      <td>0.665610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.490833</td>\n",
       "      <td>0.18360</td>\n",
       "      <td>0.6052</td>\n",
       "      <td>0.09180</td>\n",
       "      <td>0.10095</td>\n",
       "      <td>0.671707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.490833</td>\n",
       "      <td>0.18405</td>\n",
       "      <td>0.6052</td>\n",
       "      <td>0.09200</td>\n",
       "      <td>0.10120</td>\n",
       "      <td>0.671707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.490583</td>\n",
       "      <td>0.18455</td>\n",
       "      <td>0.6092</td>\n",
       "      <td>0.09225</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.677927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.492417</td>\n",
       "      <td>0.28650</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.14325</td>\n",
       "      <td>0.15755</td>\n",
       "      <td>0.967439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.492667</td>\n",
       "      <td>0.28650</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.14325</td>\n",
       "      <td>0.15755</td>\n",
       "      <td>0.967439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.492667</td>\n",
       "      <td>0.28650</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.14325</td>\n",
       "      <td>0.15755</td>\n",
       "      <td>0.967439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.492417</td>\n",
       "      <td>0.28655</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.14325</td>\n",
       "      <td>0.15760</td>\n",
       "      <td>0.967439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.492667</td>\n",
       "      <td>0.28650</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.14325</td>\n",
       "      <td>0.15755</td>\n",
       "      <td>0.967439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4345 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     WC_ratio      TEMP       EC     VWC      TDS  SALINITY   EPSILON\n",
       "0         0.4  0.491083  0.18165  0.6014  0.09080   0.09990  0.665610\n",
       "1         0.4  0.491083  0.18250  0.6014  0.09125   0.10035  0.665610\n",
       "2         0.4  0.490833  0.18360  0.6052  0.09180   0.10095  0.671707\n",
       "3         0.4  0.490833  0.18405  0.6052  0.09200   0.10120  0.671707\n",
       "4         0.4  0.490583  0.18455  0.6092  0.09225   0.10150  0.677927\n",
       "..        ...       ...      ...     ...      ...       ...       ...\n",
       "455       0.6  0.492417  0.28650  0.9488  0.14325   0.15755  0.967439\n",
       "456       0.6  0.492667  0.28650  0.9488  0.14325   0.15755  0.967439\n",
       "457       0.6  0.492667  0.28650  0.9488  0.14325   0.15755  0.967439\n",
       "458       0.6  0.492417  0.28655  0.9488  0.14325   0.15760  0.967439\n",
       "459       0.6  0.492667  0.28650  0.9488  0.14325   0.15755  0.967439\n",
       "\n",
       "[4345 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load FDR Data for Valid\n",
    "\n",
    "valid_path_list = []\n",
    "valid_path_under=os.listdir(valid_path_upper)\n",
    "\n",
    "# load data_path\n",
    "for i in range(len(valid_path_under)): # collect under directory file path\n",
    "    valid_path_sub=os.listdir(valid_path_upper+'/'+valid_path_under[i])\n",
    "    \n",
    "    for j in range(len(valid_path_sub)):\n",
    "        valid_path_list.append(valid_path_upper+'/'+valid_path_under[i]+'/'+valid_path_sub[j])\n",
    "\n",
    "# make zero matrix\n",
    "valid_data_list = [0]*len(valid_path_list)\n",
    "valid_rand_x_data_list = [0]*len(valid_path_list)\n",
    "valid_rand_y_data_list = [0]*len(valid_path_list)\n",
    "\n",
    "# load data_value\n",
    "for i,j in enumerate(valid_path_list):\n",
    "    valid_data_list[i] =pd.read_csv(j)\n",
    "    valid_data_list[i] = data_set_normalization(valid_data_list[i])\n",
    "    \n",
    "valid_data = pd.concat(valid_data_list)\n",
    "\n",
    "# Print the data format\n",
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WC_ratio</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>EC</th>\n",
       "      <th>VWC</th>\n",
       "      <th>TDS</th>\n",
       "      <th>SALINITY</th>\n",
       "      <th>EPSILON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.491500</td>\n",
       "      <td>0.15550</td>\n",
       "      <td>0.5570</td>\n",
       "      <td>0.07775</td>\n",
       "      <td>0.08550</td>\n",
       "      <td>0.585610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.491500</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.5588</td>\n",
       "      <td>0.07810</td>\n",
       "      <td>0.08590</td>\n",
       "      <td>0.589146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.491083</td>\n",
       "      <td>0.15690</td>\n",
       "      <td>0.5597</td>\n",
       "      <td>0.07845</td>\n",
       "      <td>0.08625</td>\n",
       "      <td>0.590976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.490833</td>\n",
       "      <td>0.15750</td>\n",
       "      <td>0.5597</td>\n",
       "      <td>0.07875</td>\n",
       "      <td>0.08660</td>\n",
       "      <td>0.590976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.490833</td>\n",
       "      <td>0.15805</td>\n",
       "      <td>0.5597</td>\n",
       "      <td>0.07900</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.590976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.487667</td>\n",
       "      <td>0.29310</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.14655</td>\n",
       "      <td>0.16120</td>\n",
       "      <td>0.967439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.487667</td>\n",
       "      <td>0.29355</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.14675</td>\n",
       "      <td>0.16145</td>\n",
       "      <td>0.967439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.487667</td>\n",
       "      <td>0.29400</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.14700</td>\n",
       "      <td>0.16170</td>\n",
       "      <td>0.967439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.487667</td>\n",
       "      <td>0.29355</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.14675</td>\n",
       "      <td>0.16145</td>\n",
       "      <td>0.967439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.487667</td>\n",
       "      <td>0.29355</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.14675</td>\n",
       "      <td>0.16145</td>\n",
       "      <td>0.967439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4392 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     WC_ratio      TEMP       EC     VWC      TDS  SALINITY   EPSILON\n",
       "0         0.4  0.491500  0.15550  0.5570  0.07775   0.08550  0.585610\n",
       "1         0.4  0.491500  0.15625  0.5588  0.07810   0.08590  0.589146\n",
       "2         0.4  0.491083  0.15690  0.5597  0.07845   0.08625  0.590976\n",
       "3         0.4  0.490833  0.15750  0.5597  0.07875   0.08660  0.590976\n",
       "4         0.4  0.490833  0.15805  0.5597  0.07900   0.08690  0.590976\n",
       "..        ...       ...      ...     ...      ...       ...       ...\n",
       "513       0.6  0.487667  0.29310  0.9488  0.14655   0.16120  0.967439\n",
       "514       0.6  0.487667  0.29355  0.9488  0.14675   0.16145  0.967439\n",
       "515       0.6  0.487667  0.29400  0.9488  0.14700   0.16170  0.967439\n",
       "516       0.6  0.487667  0.29355  0.9488  0.14675   0.16145  0.967439\n",
       "517       0.6  0.487667  0.29355  0.9488  0.14675   0.16145  0.967439\n",
       "\n",
       "[4392 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load FDR Data for Test\n",
    "\n",
    "test_path_list = []\n",
    "test_path_under=os.listdir(test_path_upper)\n",
    "\n",
    "# load data_path\n",
    "for i in range(len(test_path_under)): # collect under directory file path\n",
    "    test_path_sub=os.listdir(test_path_upper+'/'+test_path_under[i])\n",
    "    \n",
    "    for j in range(len(test_path_sub)):\n",
    "        test_path_list.append(test_path_upper+'/'+test_path_under[i]+'/'+test_path_sub[j])\n",
    "\n",
    "# make zero matrix\n",
    "test_data_list = [0]*len(test_path_list)\n",
    "test_rand_x_data_list = [0]*len(test_path_list)\n",
    "test_rand_y_data_list = [0]*len(test_path_list)\n",
    "\n",
    "# load data_value\n",
    "for i,j in enumerate(test_path_list):\n",
    "    test_data_list[i] =pd.read_csv(j)\n",
    "    test_data_list[i] = data_set_normalization(test_data_list[i])\n",
    "    \n",
    "test_data = pd.concat(test_data_list)\n",
    "\n",
    "# Print the data format\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT-label for Train (WCR)\n",
    "y_R = round(train_data['WC_ratio']*100, 1)\n",
    "y_train = y_R.to_numpy()\n",
    "\n",
    "# FDR sensor data for Train\n",
    "x_R = train_data[['TEMP','VWC','EPSILON','SALINITY','TDS','EC']]\n",
    "x_train = x_R.to_numpy()\n",
    "\n",
    "x_train_shuffled, y_train_shuffled = shuffle(x_train, y_train, random_state=seed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT-label for Valid (WCR)\n",
    "y_R_valid = round(valid_data['WC_ratio']*100, 1)\n",
    "y_valid = y_R_valid.to_numpy()\n",
    "\n",
    "# FDR sensor data for Valid\n",
    "x_R_valid = valid_data[['TEMP','VWC','EPSILON','SALINITY','TDS','EC']]\n",
    "x_valid = x_R_valid.to_numpy()\n",
    "\n",
    "x_valid_shuffled, y_valid_shuffled = shuffle(x_valid, y_valid, random_state=seed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT-label for Test (WCR)\n",
    "y_R_test = round(test_data['WC_ratio']*100, 1)\n",
    "y_test = y_R_test.to_numpy()\n",
    "\n",
    "# FDR sensor data for Test\n",
    "x_R_test = test_data[['TEMP','VWC','EPSILON','SALINITY','TDS','EC']]\n",
    "x_test = x_R_test.to_numpy()\n",
    "\n",
    "x_test_shuffled, y_test_shuffled = shuffle(x_test, y_test, random_state=seed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_version : 2.6.2\n"
     ]
    }
   ],
   "source": [
    "### Create WCRnet (ResNet)\n",
    "\n",
    "print(\"tf_version : %s\" %tf.__version__)\n",
    "\n",
    "def layer_1(x):    \n",
    "    x = tf.keras.layers.Dense(32, kernel_initializer='normal')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.activations.relu(x)\n",
    " \n",
    "    return x   \n",
    " \n",
    "    \n",
    "def layer_2(x):       \n",
    " \n",
    "    for i in range(layer_list[0]): \n",
    "        if i==0: \n",
    "            # upsample 32 -> 64\n",
    "            reshaped_input = tf.expand_dims(x, axis=-1)\n",
    "            upsampled_output = tf.keras.layers.UpSampling1D(size=2)(reshaped_input)\n",
    "            shortcut = tf.squeeze(upsampled_output, axis=-1)            \n",
    "        else:\n",
    "            shortcut = x\n",
    "            \n",
    "        x = tf.keras.layers.Dense(64, kernel_initializer='normal')(x)     \n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        \n",
    "        x = tf.keras.layers.Dense(64, kernel_initializer='normal')(x)     \n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        \n",
    "        x = tf.keras.layers.Add()([x, shortcut])\n",
    "        x = tf.keras.activations.relu(x)\n",
    "\n",
    "        shortcut = x\n",
    "      \n",
    "    return x\n",
    " \n",
    "  \n",
    "def layer_3(x):        \n",
    "    \n",
    "    for i in range(layer_list[1]):  \n",
    "        if i==0: \n",
    "            # upsample 64 -> 128\n",
    "            reshaped_input = tf.expand_dims(x, axis=-1)\n",
    "            upsampled_output = tf.keras.layers.UpSampling1D(size=2)(reshaped_input)\n",
    "            shortcut = tf.squeeze(upsampled_output, axis=-1)\n",
    "        else:\n",
    "            shortcut = x\n",
    "            \n",
    "        x = tf.keras.layers.Dense(128, kernel_initializer='normal')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "    \n",
    "        x = tf.keras.layers.Dense(128, kernel_initializer='normal')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)  \n",
    "\n",
    "        x = tf.keras.layers.Add()([x, shortcut])\n",
    "        x = tf.keras.activations.relu(x)\n",
    "\n",
    "        shortcut = x      \n",
    "            \n",
    "    return x\n",
    " \n",
    "  \n",
    "def layer_4(x):   \n",
    "    \n",
    "    for i in range(layer_list[2]): \n",
    "        if i==0: \n",
    "            # downsample 128 -> 64\n",
    "            reshaped_input = tf.expand_dims(x, axis=-1)\n",
    "            downsampled_output  = tf.keras.layers.UpSampling1D(size=2)(reshaped_input)\n",
    "            shortcut = tf.squeeze(downsampled_output , axis=-1)\n",
    "        else:\n",
    "            shortcut = x\n",
    "            \n",
    "        x = tf.keras.layers.Dense(256, kernel_initializer='normal')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "    \n",
    "        x = tf.keras.layers.Dense(256, kernel_initializer='normal')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)  \n",
    "\n",
    "        x = tf.keras.layers.Add()([x, shortcut])\n",
    "        x = tf.keras.activations.relu(x)\n",
    "\n",
    "        shortcut = x      \n",
    "            \n",
    "    return x\n",
    " \n",
    "  \n",
    "def layer_5(x):\n",
    "    \n",
    "    for i in range(layer_list[3]):\n",
    "        if i==0: \n",
    "            # downsample 64 -> 32\n",
    "            reshaped_input = tf.expand_dims(x, axis=-1)\n",
    "            downsampled_output  = tf.keras.layers.UpSampling1D(size=2)(reshaped_input)\n",
    "            shortcut = tf.squeeze(downsampled_output , axis=-1)\n",
    "        else:\n",
    "            shortcut = x    \n",
    "\n",
    "        x = tf.keras.layers.Dense(512, kernel_initializer='normal')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "    \n",
    "        x = tf.keras.layers.Dense(512, kernel_initializer='normal')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.activations.relu(x)  \n",
    "\n",
    "        x = tf.keras.layers.Add()([x, shortcut])\n",
    "        x = tf.keras.activations.relu(x)\n",
    "\n",
    "        shortcut = x      \n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           224         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32)           128         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu (TFOpLambda)         (None, 32)           0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           2112        tf.nn.relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64)           256         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1 (TFOpLambda)       (None, 64)           0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        tf.nn.relu_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims (TFOpLambda)     (None, 32, 1)        0           tf.nn.relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64)           256         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d (UpSampling1D)    (None, 64, 1)        0           tf.expand_dims[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_2 (TFOpLambda)       (None, 64)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambd (None, 64)           0           up_sampling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64)           0           tf.nn.relu_2[0][0]               \n",
      "                                                                 tf.compat.v1.squeeze[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_3 (TFOpLambda)       (None, 64)           0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           4160        tf.nn.relu_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64)           256         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_4 (TFOpLambda)       (None, 64)           0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           4160        tf.nn.relu_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64)           256         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_5 (TFOpLambda)       (None, 64)           0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64)           0           tf.nn.relu_5[0][0]               \n",
      "                                                                 tf.nn.relu_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_6 (TFOpLambda)       (None, 64)           0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           4160        tf.nn.relu_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64)           256         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_7 (TFOpLambda)       (None, 64)           0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           4160        tf.nn.relu_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64)           256         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_8 (TFOpLambda)       (None, 64)           0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64)           0           tf.nn.relu_8[0][0]               \n",
      "                                                                 tf.nn.relu_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_9 (TFOpLambda)       (None, 64)           0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          8320        tf.nn.relu_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128)          512         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_10 (TFOpLambda)      (None, 128)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          16512       tf.nn.relu_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_1 (TFOpLambda)   (None, 64, 1)        0           tf.nn.relu_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128)          512         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1D)  (None, 128, 1)       0           tf.expand_dims_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_11 (TFOpLambda)      (None, 128)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_1 (TFOpLam (None, 128)          0           up_sampling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128)          0           tf.nn.relu_11[0][0]              \n",
      "                                                                 tf.compat.v1.squeeze_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_12 (TFOpLambda)      (None, 128)          0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          16512       tf.nn.relu_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 128)          512         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_13 (TFOpLambda)      (None, 128)          0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128)          16512       tf.nn.relu_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128)          512         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_14 (TFOpLambda)      (None, 128)          0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128)          0           tf.nn.relu_14[0][0]              \n",
      "                                                                 tf.nn.relu_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_15 (TFOpLambda)      (None, 128)          0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 128)          16512       tf.nn.relu_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128)          512         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_16 (TFOpLambda)      (None, 128)          0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128)          16512       tf.nn.relu_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128)          512         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_17 (TFOpLambda)      (None, 128)          0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 128)          0           tf.nn.relu_17[0][0]              \n",
      "                                                                 tf.nn.relu_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_18 (TFOpLambda)      (None, 128)          0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          16512       tf.nn.relu_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128)          512         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_19 (TFOpLambda)      (None, 128)          0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 128)          16512       tf.nn.relu_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128)          512         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_20 (TFOpLambda)      (None, 128)          0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 128)          0           tf.nn.relu_20[0][0]              \n",
      "                                                                 tf.nn.relu_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_21 (TFOpLambda)      (None, 128)          0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 256)          33024       tf.nn.relu_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256)          1024        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_22 (TFOpLambda)      (None, 256)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 256)          65792       tf.nn.relu_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_2 (TFOpLambda)   (None, 128, 1)       0           tf.nn.relu_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 256)          1024        dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1D)  (None, 256, 1)       0           tf.expand_dims_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_23 (TFOpLambda)      (None, 256)          0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_2 (TFOpLam (None, 256)          0           up_sampling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 256)          0           tf.nn.relu_23[0][0]              \n",
      "                                                                 tf.compat.v1.squeeze_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_24 (TFOpLambda)      (None, 256)          0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          65792       tf.nn.relu_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256)          1024        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_25 (TFOpLambda)      (None, 256)          0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 256)          65792       tf.nn.relu_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 256)          1024        dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_26 (TFOpLambda)      (None, 256)          0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 256)          0           tf.nn.relu_26[0][0]              \n",
      "                                                                 tf.nn.relu_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_27 (TFOpLambda)      (None, 256)          0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 256)          65792       tf.nn.relu_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256)          1024        dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_28 (TFOpLambda)      (None, 256)          0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 256)          65792       tf.nn.relu_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 256)          1024        dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_29 (TFOpLambda)      (None, 256)          0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 256)          0           tf.nn.relu_29[0][0]              \n",
      "                                                                 tf.nn.relu_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_30 (TFOpLambda)      (None, 256)          0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 256)          65792       tf.nn.relu_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 256)          1024        dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_31 (TFOpLambda)      (None, 256)          0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 256)          65792       tf.nn.relu_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 256)          1024        dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_32 (TFOpLambda)      (None, 256)          0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 256)          0           tf.nn.relu_32[0][0]              \n",
      "                                                                 tf.nn.relu_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_33 (TFOpLambda)      (None, 256)          0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 256)          65792       tf.nn.relu_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 256)          1024        dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_34 (TFOpLambda)      (None, 256)          0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 256)          65792       tf.nn.relu_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 256)          1024        dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_35 (TFOpLambda)      (None, 256)          0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 256)          0           tf.nn.relu_35[0][0]              \n",
      "                                                                 tf.nn.relu_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_36 (TFOpLambda)      (None, 256)          0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 256)          65792       tf.nn.relu_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 256)          1024        dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_37 (TFOpLambda)      (None, 256)          0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 256)          65792       tf.nn.relu_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 256)          1024        dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_38 (TFOpLambda)      (None, 256)          0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 256)          0           tf.nn.relu_38[0][0]              \n",
      "                                                                 tf.nn.relu_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_39 (TFOpLambda)      (None, 256)          0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 512)          131584      tf.nn.relu_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 512)          2048        dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_40 (TFOpLambda)      (None, 512)          0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 512)          262656      tf.nn.relu_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_3 (TFOpLambda)   (None, 256, 1)       0           tf.nn.relu_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 512)          2048        dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1D)  (None, 512, 1)       0           tf.expand_dims_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_41 (TFOpLambda)      (None, 512)          0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_3 (TFOpLam (None, 512)          0           up_sampling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 512)          0           tf.nn.relu_41[0][0]              \n",
      "                                                                 tf.compat.v1.squeeze_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_42 (TFOpLambda)      (None, 512)          0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 512)          262656      tf.nn.relu_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 512)          2048        dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_43 (TFOpLambda)      (None, 512)          0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 512)          262656      tf.nn.relu_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 512)          2048        dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_44 (TFOpLambda)      (None, 512)          0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 512)          0           tf.nn.relu_44[0][0]              \n",
      "                                                                 tf.nn.relu_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_45 (TFOpLambda)      (None, 512)          0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 512)          262656      tf.nn.relu_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 512)          2048        dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_46 (TFOpLambda)      (None, 512)          0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 512)          262656      tf.nn.relu_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 512)          2048        dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_47 (TFOpLambda)      (None, 512)          0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 512)          0           tf.nn.relu_47[0][0]              \n",
      "                                                                 tf.nn.relu_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_48 (TFOpLambda)      (None, 512)          0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 1)            513         tf.nn.relu_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_49 (TFOpLambda)      (None, 1)            0           dense_33[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,379,489\n",
      "Trainable params: 2,364,321\n",
      "Non-trainable params: 15,168\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Compile WCRnet (ResNet)\n",
    "\n",
    "input_tensor =  tf.keras.Input(shape=(input_shape,))\n",
    "\n",
    "x = layer_1(input_tensor)\n",
    "x = layer_2(x)\n",
    "x = layer_3(x)\n",
    "x = layer_4(x)\n",
    "x = layer_5(x)\n",
    " \n",
    "output_tensor = tf.keras.layers.Dense(1, kernel_initializer='normal')(x)\n",
    "output_tensor = tf.keras.activations.relu(output_tensor)\n",
    "\n",
    "model = tf.keras.Model(input_tensor, output_tensor)\n",
    "model.summary()\n",
    "\n",
    "start_model=model.get_weights()\n",
    "counter  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Checkpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    model_save_dir,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "14/14 [==============================] - 10s 127ms/step - loss: 310.9785 - mae: 9.1361 - val_loss: 2518.9414 - val_mae: 49.7768\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2518.94141, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cai-sh\\anaconda3\\envs\\wc_ratio\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 7.1207 - mae: 2.0738 - val_loss: 1478.6918 - val_mae: 37.3128\n",
      "\n",
      "Epoch 00002: val_loss improved from 2518.94141 to 1478.69177, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 3/1000\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 4.6573 - mae: 1.6156 - val_loss: 872.3368 - val_mae: 28.8650\n",
      "\n",
      "Epoch 00003: val_loss improved from 1478.69177 to 872.33679, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 4/1000\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 6.0334 - mae: 1.8613 - val_loss: 593.0406 - val_mae: 23.5761\n",
      "\n",
      "Epoch 00004: val_loss improved from 872.33679 to 593.04065, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 5/1000\n",
      "14/14 [==============================] - 1s 73ms/step - loss: 3.9439 - mae: 1.5072 - val_loss: 440.5543 - val_mae: 20.1279\n",
      "\n",
      "Epoch 00005: val_loss improved from 593.04065 to 440.55426, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 6/1000\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 3.4465 - mae: 1.3773 - val_loss: 318.4249 - val_mae: 16.8110\n",
      "\n",
      "Epoch 00006: val_loss improved from 440.55426 to 318.42493, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 7/1000\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 3.8348 - mae: 1.4532 - val_loss: 248.5378 - val_mae: 14.5572\n",
      "\n",
      "Epoch 00007: val_loss improved from 318.42493 to 248.53783, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 8/1000\n",
      "14/14 [==============================] - 1s 101ms/step - loss: 6.0283 - mae: 1.8781 - val_loss: 212.0851 - val_mae: 13.1968\n",
      "\n",
      "Epoch 00008: val_loss improved from 248.53783 to 212.08505, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 9/1000\n",
      "14/14 [==============================] - 1s 70ms/step - loss: 4.6304 - mae: 1.6501 - val_loss: 159.0009 - val_mae: 10.9911\n",
      "\n",
      "Epoch 00009: val_loss improved from 212.08505 to 159.00089, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 10/1000\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 4.7137 - mae: 1.6637 - val_loss: 138.0919 - val_mae: 10.0603\n",
      "\n",
      "Epoch 00010: val_loss improved from 159.00089 to 138.09195, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 11/1000\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 4.5687 - mae: 1.6079 - val_loss: 130.1722 - val_mae: 9.6766\n",
      "\n",
      "Epoch 00011: val_loss improved from 138.09195 to 130.17220, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 12/1000\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 4.7019 - mae: 1.6471 - val_loss: 94.6278 - val_mae: 7.9612\n",
      "\n",
      "Epoch 00012: val_loss improved from 130.17220 to 94.62779, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 13/1000\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 4.2043 - mae: 1.5513 - val_loss: 97.7631 - val_mae: 8.1485\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 94.62779\n",
      "Epoch 14/1000\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 4.5430 - mae: 1.5975 - val_loss: 88.2686 - val_mae: 7.6692\n",
      "\n",
      "Epoch 00014: val_loss improved from 94.62779 to 88.26865, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 15/1000\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 4.3237 - mae: 1.5589 - val_loss: 77.6742 - val_mae: 7.1450\n",
      "\n",
      "Epoch 00015: val_loss improved from 88.26865 to 77.67419, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 16/1000\n",
      "14/14 [==============================] - 1s 90ms/step - loss: 8.6022 - mae: 2.2861 - val_loss: 48.4270 - val_mae: 5.6861\n",
      "\n",
      "Epoch 00016: val_loss improved from 77.67419 to 48.42696, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 17/1000\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 4.2452 - mae: 1.5921 - val_loss: 54.1860 - val_mae: 5.9553\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 48.42696\n",
      "Epoch 18/1000\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 4.3035 - mae: 1.5550 - val_loss: 71.8242 - val_mae: 6.8581\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 48.42696\n",
      "Epoch 19/1000\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 6.6145 - mae: 2.0646 - val_loss: 56.0104 - val_mae: 6.1337\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 48.42696\n",
      "Epoch 20/1000\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 4.0687 - mae: 1.5476 - val_loss: 63.0651 - val_mae: 6.5485\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 48.42696\n",
      "Epoch 21/1000\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 3.3602 - mae: 1.3635 - val_loss: 54.0485 - val_mae: 6.0281\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 48.42696\n",
      "Epoch 22/1000\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 3.8479 - mae: 1.4695 - val_loss: 41.6551 - val_mae: 5.3211\n",
      "\n",
      "Epoch 00022: val_loss improved from 48.42696 to 41.65508, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 23/1000\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 4.1751 - mae: 1.5469 - val_loss: 41.6497 - val_mae: 5.3189\n",
      "\n",
      "Epoch 00023: val_loss improved from 41.65508 to 41.64972, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 24/1000\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 5.6011 - mae: 1.8114 - val_loss: 63.8082 - val_mae: 6.5594\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 41.64972\n",
      "Epoch 25/1000\n",
      "14/14 [==============================] - 1s 87ms/step - loss: 6.0644 - mae: 1.8479 - val_loss: 38.5718 - val_mae: 5.2910\n",
      "\n",
      "Epoch 00025: val_loss improved from 41.64972 to 38.57182, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 26/1000\n",
      "14/14 [==============================] - 1s 72ms/step - loss: 4.5175 - mae: 1.6005 - val_loss: 50.3472 - val_mae: 5.8353\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 38.57182\n",
      "Epoch 27/1000\n",
      "14/14 [==============================] - 1s 70ms/step - loss: 3.4348 - mae: 1.3555 - val_loss: 40.1485 - val_mae: 5.3132\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 38.57182\n",
      "Epoch 28/1000\n",
      "14/14 [==============================] - 1s 69ms/step - loss: 3.5722 - mae: 1.4253 - val_loss: 35.4199 - val_mae: 4.9875\n",
      "\n",
      "Epoch 00028: val_loss improved from 38.57182 to 35.41992, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 29/1000\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 3.4888 - mae: 1.3909 - val_loss: 32.5120 - val_mae: 4.7982\n",
      "\n",
      "Epoch 00029: val_loss improved from 35.41992 to 32.51195, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 30/1000\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 3.4545 - mae: 1.3894 - val_loss: 30.8871 - val_mae: 4.6351\n",
      "\n",
      "Epoch 00030: val_loss improved from 32.51195 to 30.88707, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 31/1000\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 3.0077 - mae: 1.2603 - val_loss: 30.2754 - val_mae: 4.5977\n",
      "\n",
      "Epoch 00031: val_loss improved from 30.88707 to 30.27538, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 32/1000\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 3.6837 - mae: 1.4270 - val_loss: 32.1510 - val_mae: 4.6914\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 30.27538\n",
      "Epoch 33/1000\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 3.2048 - mae: 1.3095 - val_loss: 24.9843 - val_mae: 4.1764\n",
      "\n",
      "Epoch 00033: val_loss improved from 30.27538 to 24.98425, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 34/1000\n",
      "14/14 [==============================] - 1s 88ms/step - loss: 3.4131 - mae: 1.3578 - val_loss: 20.9946 - val_mae: 3.8417\n",
      "\n",
      "Epoch 00034: val_loss improved from 24.98425 to 20.99463, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 35/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 66ms/step - loss: 3.5896 - mae: 1.4089 - val_loss: 23.5551 - val_mae: 3.9875\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 20.99463\n",
      "Epoch 36/1000\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 3.4478 - mae: 1.3867 - val_loss: 15.8443 - val_mae: 3.4377\n",
      "\n",
      "Epoch 00036: val_loss improved from 20.99463 to 15.84427, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 37/1000\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 3.2149 - mae: 1.3288 - val_loss: 14.1580 - val_mae: 3.2604\n",
      "\n",
      "Epoch 00037: val_loss improved from 15.84427 to 14.15800, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 38/1000\n",
      "14/14 [==============================] - 1s 91ms/step - loss: 3.1555 - mae: 1.2727 - val_loss: 15.2758 - val_mae: 3.3647\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 14.15800\n",
      "Epoch 39/1000\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 4.0161 - mae: 1.5234 - val_loss: 9.4828 - val_mae: 2.6869\n",
      "\n",
      "Epoch 00039: val_loss improved from 14.15800 to 9.48283, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 40/1000\n",
      "14/14 [==============================] - 1s 89ms/step - loss: 3.2520 - mae: 1.2929 - val_loss: 5.7793 - val_mae: 2.1067\n",
      "\n",
      "Epoch 00040: val_loss improved from 9.48283 to 5.77930, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 41/1000\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 3.4257 - mae: 1.3663 - val_loss: 5.7257 - val_mae: 2.0416\n",
      "\n",
      "Epoch 00041: val_loss improved from 5.77930 to 5.72574, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 42/1000\n",
      "14/14 [==============================] - 1s 80ms/step - loss: 3.2487 - mae: 1.3527 - val_loss: 4.3857 - val_mae: 1.7257\n",
      "\n",
      "Epoch 00042: val_loss improved from 5.72574 to 4.38568, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 43/1000\n",
      "14/14 [==============================] - 1s 96ms/step - loss: 3.3900 - mae: 1.3450 - val_loss: 3.9200 - val_mae: 1.6374\n",
      "\n",
      "Epoch 00043: val_loss improved from 4.38568 to 3.92004, saving model to C:\\Users\\cai-sh\\Desktop\\WCRnet/save_models\\WCRnet_ResNet.h5\n",
      "Epoch 44/1000\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 3.8209 - mae: 1.4519 - val_loss: 6.0111 - val_mae: 1.9761\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.92004\n",
      "Epoch 45/1000\n",
      " 7/14 [==============>...............] - ETA: 0s - loss: 3.1563 - mae: 1.2900"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8eee78d17d6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_shuffled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_shuffled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid_shuffled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid_shuffled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\wc_ratio\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wc_ratio\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wc_ratio\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wc_ratio\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wc_ratio\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wc_ratio\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\wc_ratio\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Training WCRnet\n",
    "\n",
    "train_mode = True\n",
    "\n",
    "if train_mode == True:\n",
    "\n",
    "    # Load the learning rate scheduler    \n",
    "    lr_s = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=initial_learning_rate,\n",
    "        decay_steps=10,\n",
    "        decay_rate=0.95,\n",
    "        staircase=True\n",
    "    )\n",
    "\n",
    "    # Load the Early Stopping\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(patience=300, min_delta=3, monitor='val_loss')    \n",
    "    \n",
    "    # model compile\n",
    "    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=lr_s), metrics=['mae'])\n",
    "    \n",
    "    # training\n",
    "    history = model.fit(x_train_shuffled, y_train_shuffled, validation_data=(x_valid_shuffled, y_valid_shuffled), epochs=epochs, batch_size=batch_sizes, callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the Loss graph\n",
    "\n",
    "if train_mode == True:\n",
    "    plt.subplots(figsize=(6,4.5))\n",
    "    plt.plot(history.history['loss'],'b-',label='train_loss')\n",
    "    plt.plot(history.history['val_loss'],'b-',label='val_loss',color='r')\n",
    "\n",
    "    plt.legend(prop={'size': 20})\n",
    "\n",
    "    plt.xlabel(\"Epoch\", fontdict={'size': 20})\n",
    "    plt.ylabel(\"Loss\", fontdict={'size': 20})\n",
    "\n",
    "    plt.xticks((0, 200, 400, 600, 800, 1000),fontsize=15)\n",
    "    plt.yticks((0, 1000, 2000, 3000, 4000, 5000),fontsize=15)\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print the prediction results\n",
    "\n",
    "test_losses = []\n",
    "p_result_0 = []\n",
    "\n",
    "# Load Model & Make Results\n",
    "model.load_weights(model_save_dir)\n",
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "test_losses = model.evaluate(x_test_shuffled, y_test_shuffled, verbose=0)\n",
    "p_result_0 = model.predict(x_test_shuffled)\n",
    "\n",
    "p_result_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### print RMSE and R2-score\n",
    "\n",
    "rmse_0 = round(mean_squared_error(y_test_shuffled, p_result_0, squared=False), 4)\n",
    "r2_0 = round(r2_score(y_test_shuffled, p_result_0), 4)\n",
    "\n",
    "print(f\"RMSE : {rmse_0}\")\n",
    "print(f\"r2_score : {r2_0}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
